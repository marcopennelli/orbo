// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.11
// 	protoc        v6.33.1
// source: api/proto/recognition/v1/recognition.proto

package recognitionv1

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// FaceRequest contains a video frame or crop regions to be processed
type FaceRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Camera identifier
	CameraId string `protobuf:"bytes,1,opt,name=camera_id,json=cameraId,proto3" json:"camera_id,omitempty"`
	// Frame sequence number for ordering validation
	FrameSeq uint64 `protobuf:"varint,2,opt,name=frame_seq,json=frameSeq,proto3" json:"frame_seq,omitempty"`
	// Capture timestamp in nanoseconds since epoch
	TimestampNs int64 `protobuf:"varint,3,opt,name=timestamp_ns,json=timestampNs,proto3" json:"timestamp_ns,omitempty"`
	// JPEG-encoded frame data
	JpegData []byte `protobuf:"bytes,4,opt,name=jpeg_data,json=jpegData,proto3" json:"jpeg_data,omitempty"`
	// Request annotated image with face boxes drawn
	ReturnAnnotated bool `protobuf:"varint,5,opt,name=return_annotated,json=returnAnnotated,proto3" json:"return_annotated,omitempty"`
	// Similarity threshold for face matching (0-1)
	SimilarityThreshold float32 `protobuf:"fixed32,6,opt,name=similarity_threshold,json=similarityThreshold,proto3" json:"similarity_threshold,omitempty"`
	// Optional: crop regions from YOLO (person bboxes)
	// If provided, only search for faces within these regions
	PersonRegions []*BBox `protobuf:"bytes,7,rep,name=person_regions,json=personRegions,proto3" json:"person_regions,omitempty"`
	// Track IDs from YOLO for face-track association
	PersonTrackIds []int32 `protobuf:"varint,8,rep,packed,name=person_track_ids,json=personTrackIds,proto3" json:"person_track_ids,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *FaceRequest) Reset() {
	*x = FaceRequest{}
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *FaceRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FaceRequest) ProtoMessage() {}

func (x *FaceRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FaceRequest.ProtoReflect.Descriptor instead.
func (*FaceRequest) Descriptor() ([]byte, []int) {
	return file_api_proto_recognition_v1_recognition_proto_rawDescGZIP(), []int{0}
}

func (x *FaceRequest) GetCameraId() string {
	if x != nil {
		return x.CameraId
	}
	return ""
}

func (x *FaceRequest) GetFrameSeq() uint64 {
	if x != nil {
		return x.FrameSeq
	}
	return 0
}

func (x *FaceRequest) GetTimestampNs() int64 {
	if x != nil {
		return x.TimestampNs
	}
	return 0
}

func (x *FaceRequest) GetJpegData() []byte {
	if x != nil {
		return x.JpegData
	}
	return nil
}

func (x *FaceRequest) GetReturnAnnotated() bool {
	if x != nil {
		return x.ReturnAnnotated
	}
	return false
}

func (x *FaceRequest) GetSimilarityThreshold() float32 {
	if x != nil {
		return x.SimilarityThreshold
	}
	return 0
}

func (x *FaceRequest) GetPersonRegions() []*BBox {
	if x != nil {
		return x.PersonRegions
	}
	return nil
}

func (x *FaceRequest) GetPersonTrackIds() []int32 {
	if x != nil {
		return x.PersonTrackIds
	}
	return nil
}

// BBox represents a bounding box
type BBox struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	X1            float32                `protobuf:"fixed32,1,opt,name=x1,proto3" json:"x1,omitempty"` // Left
	Y1            float32                `protobuf:"fixed32,2,opt,name=y1,proto3" json:"y1,omitempty"` // Top
	X2            float32                `protobuf:"fixed32,3,opt,name=x2,proto3" json:"x2,omitempty"` // Right
	Y2            float32                `protobuf:"fixed32,4,opt,name=y2,proto3" json:"y2,omitempty"` // Bottom
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *BBox) Reset() {
	*x = BBox{}
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *BBox) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*BBox) ProtoMessage() {}

func (x *BBox) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use BBox.ProtoReflect.Descriptor instead.
func (*BBox) Descriptor() ([]byte, []int) {
	return file_api_proto_recognition_v1_recognition_proto_rawDescGZIP(), []int{1}
}

func (x *BBox) GetX1() float32 {
	if x != nil {
		return x.X1
	}
	return 0
}

func (x *BBox) GetY1() float32 {
	if x != nil {
		return x.Y1
	}
	return 0
}

func (x *BBox) GetX2() float32 {
	if x != nil {
		return x.X2
	}
	return 0
}

func (x *BBox) GetY2() float32 {
	if x != nil {
		return x.Y2
	}
	return 0
}

// FaceResponse contains face recognition results for a processed frame
type FaceResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Camera identifier (echoed from request)
	CameraId string `protobuf:"bytes,1,opt,name=camera_id,json=cameraId,proto3" json:"camera_id,omitempty"`
	// Frame sequence number (echoed from request)
	FrameSeq uint64 `protobuf:"varint,2,opt,name=frame_seq,json=frameSeq,proto3" json:"frame_seq,omitempty"`
	// Original capture timestamp
	CaptureTimestampNs int64 `protobuf:"varint,3,opt,name=capture_timestamp_ns,json=captureTimestampNs,proto3" json:"capture_timestamp_ns,omitempty"`
	// When inference completed
	InferenceTimestampNs int64 `protobuf:"varint,4,opt,name=inference_timestamp_ns,json=inferenceTimestampNs,proto3" json:"inference_timestamp_ns,omitempty"`
	// Recognized faces
	Faces []*FaceRecognition `protobuf:"bytes,5,rep,name=faces,proto3" json:"faces,omitempty"`
	// Annotated JPEG image with face boxes (if requested)
	AnnotatedJpeg []byte `protobuf:"bytes,6,opt,name=annotated_jpeg,json=annotatedJpeg,proto3" json:"annotated_jpeg,omitempty"`
	// Inference time in milliseconds
	InferenceMs float32 `protobuf:"fixed32,7,opt,name=inference_ms,json=inferenceMs,proto3" json:"inference_ms,omitempty"`
	// Device used for inference (cuda, cpu, etc.)
	Device string `protobuf:"bytes,8,opt,name=device,proto3" json:"device,omitempty"`
	// Summary counts
	TotalCount    int32 `protobuf:"varint,9,opt,name=total_count,json=totalCount,proto3" json:"total_count,omitempty"`
	KnownCount    int32 `protobuf:"varint,10,opt,name=known_count,json=knownCount,proto3" json:"known_count,omitempty"`
	UnknownCount  int32 `protobuf:"varint,11,opt,name=unknown_count,json=unknownCount,proto3" json:"unknown_count,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *FaceResponse) Reset() {
	*x = FaceResponse{}
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *FaceResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FaceResponse) ProtoMessage() {}

func (x *FaceResponse) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FaceResponse.ProtoReflect.Descriptor instead.
func (*FaceResponse) Descriptor() ([]byte, []int) {
	return file_api_proto_recognition_v1_recognition_proto_rawDescGZIP(), []int{2}
}

func (x *FaceResponse) GetCameraId() string {
	if x != nil {
		return x.CameraId
	}
	return ""
}

func (x *FaceResponse) GetFrameSeq() uint64 {
	if x != nil {
		return x.FrameSeq
	}
	return 0
}

func (x *FaceResponse) GetCaptureTimestampNs() int64 {
	if x != nil {
		return x.CaptureTimestampNs
	}
	return 0
}

func (x *FaceResponse) GetInferenceTimestampNs() int64 {
	if x != nil {
		return x.InferenceTimestampNs
	}
	return 0
}

func (x *FaceResponse) GetFaces() []*FaceRecognition {
	if x != nil {
		return x.Faces
	}
	return nil
}

func (x *FaceResponse) GetAnnotatedJpeg() []byte {
	if x != nil {
		return x.AnnotatedJpeg
	}
	return nil
}

func (x *FaceResponse) GetInferenceMs() float32 {
	if x != nil {
		return x.InferenceMs
	}
	return 0
}

func (x *FaceResponse) GetDevice() string {
	if x != nil {
		return x.Device
	}
	return ""
}

func (x *FaceResponse) GetTotalCount() int32 {
	if x != nil {
		return x.TotalCount
	}
	return 0
}

func (x *FaceResponse) GetKnownCount() int32 {
	if x != nil {
		return x.KnownCount
	}
	return 0
}

func (x *FaceResponse) GetUnknownCount() int32 {
	if x != nil {
		return x.UnknownCount
	}
	return 0
}

// FaceRecognition represents a single detected and/or recognized face
type FaceRecognition struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Bounding box in pixel coordinates
	Bbox *BBox `protobuf:"bytes,1,opt,name=bbox,proto3" json:"bbox,omitempty"`
	// Face detection confidence (0-1)
	Confidence float32 `protobuf:"fixed32,2,opt,name=confidence,proto3" json:"confidence,omitempty"`
	// Recognized identity (empty if unknown)
	Identity string `protobuf:"bytes,3,opt,name=identity,proto3" json:"identity,omitempty"`
	// Similarity score to matched face (0-1)
	Similarity float32 `protobuf:"fixed32,4,opt,name=similarity,proto3" json:"similarity,omitempty"`
	// Whether this face matched a known identity
	IsKnown bool `protobuf:"varint,5,opt,name=is_known,json=isKnown,proto3" json:"is_known,omitempty"`
	// Estimated age (0 if not available)
	Age int32 `protobuf:"varint,6,opt,name=age,proto3" json:"age,omitempty"`
	// Estimated gender (empty if not available)
	Gender string `protobuf:"bytes,7,opt,name=gender,proto3" json:"gender,omitempty"`
	// Associated YOLO person track ID (0 if not associated)
	AssociatedTrackId int32 `protobuf:"varint,8,opt,name=associated_track_id,json=associatedTrackId,proto3" json:"associated_track_id,omitempty"`
	// Face embedding vector (optional, for debugging/analysis)
	Embedding     []float32 `protobuf:"fixed32,9,rep,packed,name=embedding,proto3" json:"embedding,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *FaceRecognition) Reset() {
	*x = FaceRecognition{}
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *FaceRecognition) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FaceRecognition) ProtoMessage() {}

func (x *FaceRecognition) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FaceRecognition.ProtoReflect.Descriptor instead.
func (*FaceRecognition) Descriptor() ([]byte, []int) {
	return file_api_proto_recognition_v1_recognition_proto_rawDescGZIP(), []int{3}
}

func (x *FaceRecognition) GetBbox() *BBox {
	if x != nil {
		return x.Bbox
	}
	return nil
}

func (x *FaceRecognition) GetConfidence() float32 {
	if x != nil {
		return x.Confidence
	}
	return 0
}

func (x *FaceRecognition) GetIdentity() string {
	if x != nil {
		return x.Identity
	}
	return ""
}

func (x *FaceRecognition) GetSimilarity() float32 {
	if x != nil {
		return x.Similarity
	}
	return 0
}

func (x *FaceRecognition) GetIsKnown() bool {
	if x != nil {
		return x.IsKnown
	}
	return false
}

func (x *FaceRecognition) GetAge() int32 {
	if x != nil {
		return x.Age
	}
	return 0
}

func (x *FaceRecognition) GetGender() string {
	if x != nil {
		return x.Gender
	}
	return ""
}

func (x *FaceRecognition) GetAssociatedTrackId() int32 {
	if x != nil {
		return x.AssociatedTrackId
	}
	return 0
}

func (x *FaceRecognition) GetEmbedding() []float32 {
	if x != nil {
		return x.Embedding
	}
	return nil
}

// RegisterFaceRequest adds a new face identity
type RegisterFaceRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Name/identity to associate with this face
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// JPEG image containing exactly one face
	ImageData []byte `protobuf:"bytes,2,opt,name=image_data,json=imageData,proto3" json:"image_data,omitempty"`
	// Optional metadata
	Metadata      map[string]string `protobuf:"bytes,3,rep,name=metadata,proto3" json:"metadata,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"bytes,2,opt,name=value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RegisterFaceRequest) Reset() {
	*x = RegisterFaceRequest{}
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RegisterFaceRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RegisterFaceRequest) ProtoMessage() {}

func (x *RegisterFaceRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RegisterFaceRequest.ProtoReflect.Descriptor instead.
func (*RegisterFaceRequest) Descriptor() ([]byte, []int) {
	return file_api_proto_recognition_v1_recognition_proto_rawDescGZIP(), []int{4}
}

func (x *RegisterFaceRequest) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *RegisterFaceRequest) GetImageData() []byte {
	if x != nil {
		return x.ImageData
	}
	return nil
}

func (x *RegisterFaceRequest) GetMetadata() map[string]string {
	if x != nil {
		return x.Metadata
	}
	return nil
}

// RegisterFaceResponse confirms face registration
type RegisterFaceResponse struct {
	state   protoimpl.MessageState `protogen:"open.v1"`
	Success bool                   `protobuf:"varint,1,opt,name=success,proto3" json:"success,omitempty"`
	Message string                 `protobuf:"bytes,2,opt,name=message,proto3" json:"message,omitempty"`
	// Registered name
	Name string `protobuf:"bytes,3,opt,name=name,proto3" json:"name,omitempty"`
	// Total faces in database after registration
	FaceCount     int32 `protobuf:"varint,4,opt,name=face_count,json=faceCount,proto3" json:"face_count,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RegisterFaceResponse) Reset() {
	*x = RegisterFaceResponse{}
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RegisterFaceResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RegisterFaceResponse) ProtoMessage() {}

func (x *RegisterFaceResponse) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RegisterFaceResponse.ProtoReflect.Descriptor instead.
func (*RegisterFaceResponse) Descriptor() ([]byte, []int) {
	return file_api_proto_recognition_v1_recognition_proto_rawDescGZIP(), []int{5}
}

func (x *RegisterFaceResponse) GetSuccess() bool {
	if x != nil {
		return x.Success
	}
	return false
}

func (x *RegisterFaceResponse) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

func (x *RegisterFaceResponse) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *RegisterFaceResponse) GetFaceCount() int32 {
	if x != nil {
		return x.FaceCount
	}
	return 0
}

// DeleteFaceRequest removes a face identity
type DeleteFaceRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Name of the face to delete
	Name          string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DeleteFaceRequest) Reset() {
	*x = DeleteFaceRequest{}
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DeleteFaceRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DeleteFaceRequest) ProtoMessage() {}

func (x *DeleteFaceRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DeleteFaceRequest.ProtoReflect.Descriptor instead.
func (*DeleteFaceRequest) Descriptor() ([]byte, []int) {
	return file_api_proto_recognition_v1_recognition_proto_rawDescGZIP(), []int{6}
}

func (x *DeleteFaceRequest) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

// DeleteFaceResponse confirms face deletion
type DeleteFaceResponse struct {
	state   protoimpl.MessageState `protogen:"open.v1"`
	Success bool                   `protobuf:"varint,1,opt,name=success,proto3" json:"success,omitempty"`
	Message string                 `protobuf:"bytes,2,opt,name=message,proto3" json:"message,omitempty"`
	// Remaining faces in database
	FaceCount     int32 `protobuf:"varint,3,opt,name=face_count,json=faceCount,proto3" json:"face_count,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *DeleteFaceResponse) Reset() {
	*x = DeleteFaceResponse{}
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *DeleteFaceResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*DeleteFaceResponse) ProtoMessage() {}

func (x *DeleteFaceResponse) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use DeleteFaceResponse.ProtoReflect.Descriptor instead.
func (*DeleteFaceResponse) Descriptor() ([]byte, []int) {
	return file_api_proto_recognition_v1_recognition_proto_rawDescGZIP(), []int{7}
}

func (x *DeleteFaceResponse) GetSuccess() bool {
	if x != nil {
		return x.Success
	}
	return false
}

func (x *DeleteFaceResponse) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

func (x *DeleteFaceResponse) GetFaceCount() int32 {
	if x != nil {
		return x.FaceCount
	}
	return 0
}

// ListFacesRequest is empty - returns all registered faces
type ListFacesRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListFacesRequest) Reset() {
	*x = ListFacesRequest{}
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListFacesRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListFacesRequest) ProtoMessage() {}

func (x *ListFacesRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListFacesRequest.ProtoReflect.Descriptor instead.
func (*ListFacesRequest) Descriptor() ([]byte, []int) {
	return file_api_proto_recognition_v1_recognition_proto_rawDescGZIP(), []int{8}
}

// ListFacesResponse contains all registered face identities
type ListFacesResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Faces         []*FaceIdentity        `protobuf:"bytes,1,rep,name=faces,proto3" json:"faces,omitempty"`
	Count         int32                  `protobuf:"varint,2,opt,name=count,proto3" json:"count,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListFacesResponse) Reset() {
	*x = ListFacesResponse{}
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListFacesResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListFacesResponse) ProtoMessage() {}

func (x *ListFacesResponse) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListFacesResponse.ProtoReflect.Descriptor instead.
func (*ListFacesResponse) Descriptor() ([]byte, []int) {
	return file_api_proto_recognition_v1_recognition_proto_rawDescGZIP(), []int{9}
}

func (x *ListFacesResponse) GetFaces() []*FaceIdentity {
	if x != nil {
		return x.Faces
	}
	return nil
}

func (x *ListFacesResponse) GetCount() int32 {
	if x != nil {
		return x.Count
	}
	return 0
}

// FaceIdentity represents a registered face in the database
type FaceIdentity struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Identity name
	Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	// When this face was registered
	CreatedAtNs int64 `protobuf:"varint,2,opt,name=created_at_ns,json=createdAtNs,proto3" json:"created_at_ns,omitempty"`
	// Whether the face image is available
	HasImage bool `protobuf:"varint,3,opt,name=has_image,json=hasImage,proto3" json:"has_image,omitempty"`
	// Stored age/gender if captured during registration
	Age           int32  `protobuf:"varint,4,opt,name=age,proto3" json:"age,omitempty"`
	Gender        string `protobuf:"bytes,5,opt,name=gender,proto3" json:"gender,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *FaceIdentity) Reset() {
	*x = FaceIdentity{}
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *FaceIdentity) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*FaceIdentity) ProtoMessage() {}

func (x *FaceIdentity) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use FaceIdentity.ProtoReflect.Descriptor instead.
func (*FaceIdentity) Descriptor() ([]byte, []int) {
	return file_api_proto_recognition_v1_recognition_proto_rawDescGZIP(), []int{10}
}

func (x *FaceIdentity) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *FaceIdentity) GetCreatedAtNs() int64 {
	if x != nil {
		return x.CreatedAtNs
	}
	return 0
}

func (x *FaceIdentity) GetHasImage() bool {
	if x != nil {
		return x.HasImage
	}
	return false
}

func (x *FaceIdentity) GetAge() int32 {
	if x != nil {
		return x.Age
	}
	return 0
}

func (x *FaceIdentity) GetGender() string {
	if x != nil {
		return x.Gender
	}
	return ""
}

// HealthRequest is empty - just checks service availability
type HealthRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *HealthRequest) Reset() {
	*x = HealthRequest{}
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HealthRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HealthRequest) ProtoMessage() {}

func (x *HealthRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HealthRequest.ProtoReflect.Descriptor instead.
func (*HealthRequest) Descriptor() ([]byte, []int) {
	return file_api_proto_recognition_v1_recognition_proto_rawDescGZIP(), []int{11}
}

// HealthResponse contains service health status
type HealthResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Service status: healthy, unhealthy, degraded
	Status string `protobuf:"bytes,1,opt,name=status,proto3" json:"status,omitempty"`
	// Device being used (cuda, cpu, rocm)
	Device string `protobuf:"bytes,2,opt,name=device,proto3" json:"device,omitempty"`
	// Whether the model is loaded and ready
	ModelLoaded bool `protobuf:"varint,3,opt,name=model_loaded,json=modelLoaded,proto3" json:"model_loaded,omitempty"`
	// Number of registered face identities
	KnownFacesCount int32 `protobuf:"varint,4,opt,name=known_faces_count,json=knownFacesCount,proto3" json:"known_faces_count,omitempty"`
	// Model name being used
	ModelName     string `protobuf:"bytes,5,opt,name=model_name,json=modelName,proto3" json:"model_name,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *HealthResponse) Reset() {
	*x = HealthResponse{}
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *HealthResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*HealthResponse) ProtoMessage() {}

func (x *HealthResponse) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use HealthResponse.ProtoReflect.Descriptor instead.
func (*HealthResponse) Descriptor() ([]byte, []int) {
	return file_api_proto_recognition_v1_recognition_proto_rawDescGZIP(), []int{12}
}

func (x *HealthResponse) GetStatus() string {
	if x != nil {
		return x.Status
	}
	return ""
}

func (x *HealthResponse) GetDevice() string {
	if x != nil {
		return x.Device
	}
	return ""
}

func (x *HealthResponse) GetModelLoaded() bool {
	if x != nil {
		return x.ModelLoaded
	}
	return false
}

func (x *HealthResponse) GetKnownFacesCount() int32 {
	if x != nil {
		return x.KnownFacesCount
	}
	return 0
}

func (x *HealthResponse) GetModelName() string {
	if x != nil {
		return x.ModelName
	}
	return ""
}

// ConfigureRequest updates recognition parameters
type ConfigureRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Similarity threshold for face matching (0-1)
	SimilarityThreshold *float32 `protobuf:"fixed32,1,opt,name=similarity_threshold,json=similarityThreshold,proto3,oneof" json:"similarity_threshold,omitempty"`
	// Enable age/gender estimation
	EnableAgeGender *bool `protobuf:"varint,2,opt,name=enable_age_gender,json=enableAgeGender,proto3,oneof" json:"enable_age_gender,omitempty"`
	unknownFields   protoimpl.UnknownFields
	sizeCache       protoimpl.SizeCache
}

func (x *ConfigureRequest) Reset() {
	*x = ConfigureRequest{}
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ConfigureRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ConfigureRequest) ProtoMessage() {}

func (x *ConfigureRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ConfigureRequest.ProtoReflect.Descriptor instead.
func (*ConfigureRequest) Descriptor() ([]byte, []int) {
	return file_api_proto_recognition_v1_recognition_proto_rawDescGZIP(), []int{13}
}

func (x *ConfigureRequest) GetSimilarityThreshold() float32 {
	if x != nil && x.SimilarityThreshold != nil {
		return *x.SimilarityThreshold
	}
	return 0
}

func (x *ConfigureRequest) GetEnableAgeGender() bool {
	if x != nil && x.EnableAgeGender != nil {
		return *x.EnableAgeGender
	}
	return false
}

// ConfigureResponse confirms configuration update
type ConfigureResponse struct {
	state   protoimpl.MessageState `protogen:"open.v1"`
	Success bool                   `protobuf:"varint,1,opt,name=success,proto3" json:"success,omitempty"`
	Message string                 `protobuf:"bytes,2,opt,name=message,proto3" json:"message,omitempty"`
	// Current configuration after update
	SimilarityThreshold float32 `protobuf:"fixed32,3,opt,name=similarity_threshold,json=similarityThreshold,proto3" json:"similarity_threshold,omitempty"`
	AgeGenderEnabled    bool    `protobuf:"varint,4,opt,name=age_gender_enabled,json=ageGenderEnabled,proto3" json:"age_gender_enabled,omitempty"`
	unknownFields       protoimpl.UnknownFields
	sizeCache           protoimpl.SizeCache
}

func (x *ConfigureResponse) Reset() {
	*x = ConfigureResponse{}
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[14]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ConfigureResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ConfigureResponse) ProtoMessage() {}

func (x *ConfigureResponse) ProtoReflect() protoreflect.Message {
	mi := &file_api_proto_recognition_v1_recognition_proto_msgTypes[14]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ConfigureResponse.ProtoReflect.Descriptor instead.
func (*ConfigureResponse) Descriptor() ([]byte, []int) {
	return file_api_proto_recognition_v1_recognition_proto_rawDescGZIP(), []int{14}
}

func (x *ConfigureResponse) GetSuccess() bool {
	if x != nil {
		return x.Success
	}
	return false
}

func (x *ConfigureResponse) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

func (x *ConfigureResponse) GetSimilarityThreshold() float32 {
	if x != nil {
		return x.SimilarityThreshold
	}
	return 0
}

func (x *ConfigureResponse) GetAgeGenderEnabled() bool {
	if x != nil {
		return x.AgeGenderEnabled
	}
	return false
}

var File_api_proto_recognition_v1_recognition_proto protoreflect.FileDescriptor

const file_api_proto_recognition_v1_recognition_proto_rawDesc = "" +
	"\n" +
	"*api/proto/recognition/v1/recognition.proto\x12\x13orbo.recognition.v1\"\xd1\x02\n" +
	"\vFaceRequest\x12\x1b\n" +
	"\tcamera_id\x18\x01 \x01(\tR\bcameraId\x12\x1b\n" +
	"\tframe_seq\x18\x02 \x01(\x04R\bframeSeq\x12!\n" +
	"\ftimestamp_ns\x18\x03 \x01(\x03R\vtimestampNs\x12\x1b\n" +
	"\tjpeg_data\x18\x04 \x01(\fR\bjpegData\x12)\n" +
	"\x10return_annotated\x18\x05 \x01(\bR\x0freturnAnnotated\x121\n" +
	"\x14similarity_threshold\x18\x06 \x01(\x02R\x13similarityThreshold\x12@\n" +
	"\x0eperson_regions\x18\a \x03(\v2\x19.orbo.recognition.v1.BBoxR\rpersonRegions\x12(\n" +
	"\x10person_track_ids\x18\b \x03(\x05R\x0epersonTrackIds\"F\n" +
	"\x04BBox\x12\x0e\n" +
	"\x02x1\x18\x01 \x01(\x02R\x02x1\x12\x0e\n" +
	"\x02y1\x18\x02 \x01(\x02R\x02y1\x12\x0e\n" +
	"\x02x2\x18\x03 \x01(\x02R\x02x2\x12\x0e\n" +
	"\x02y2\x18\x04 \x01(\x02R\x02y2\"\xb5\x03\n" +
	"\fFaceResponse\x12\x1b\n" +
	"\tcamera_id\x18\x01 \x01(\tR\bcameraId\x12\x1b\n" +
	"\tframe_seq\x18\x02 \x01(\x04R\bframeSeq\x120\n" +
	"\x14capture_timestamp_ns\x18\x03 \x01(\x03R\x12captureTimestampNs\x124\n" +
	"\x16inference_timestamp_ns\x18\x04 \x01(\x03R\x14inferenceTimestampNs\x12:\n" +
	"\x05faces\x18\x05 \x03(\v2$.orbo.recognition.v1.FaceRecognitionR\x05faces\x12%\n" +
	"\x0eannotated_jpeg\x18\x06 \x01(\fR\rannotatedJpeg\x12!\n" +
	"\finference_ms\x18\a \x01(\x02R\vinferenceMs\x12\x16\n" +
	"\x06device\x18\b \x01(\tR\x06device\x12\x1f\n" +
	"\vtotal_count\x18\t \x01(\x05R\n" +
	"totalCount\x12\x1f\n" +
	"\vknown_count\x18\n" +
	" \x01(\x05R\n" +
	"knownCount\x12#\n" +
	"\runknown_count\x18\v \x01(\x05R\funknownCount\"\xaf\x02\n" +
	"\x0fFaceRecognition\x12-\n" +
	"\x04bbox\x18\x01 \x01(\v2\x19.orbo.recognition.v1.BBoxR\x04bbox\x12\x1e\n" +
	"\n" +
	"confidence\x18\x02 \x01(\x02R\n" +
	"confidence\x12\x1a\n" +
	"\bidentity\x18\x03 \x01(\tR\bidentity\x12\x1e\n" +
	"\n" +
	"similarity\x18\x04 \x01(\x02R\n" +
	"similarity\x12\x19\n" +
	"\bis_known\x18\x05 \x01(\bR\aisKnown\x12\x10\n" +
	"\x03age\x18\x06 \x01(\x05R\x03age\x12\x16\n" +
	"\x06gender\x18\a \x01(\tR\x06gender\x12.\n" +
	"\x13associated_track_id\x18\b \x01(\x05R\x11associatedTrackId\x12\x1c\n" +
	"\tembedding\x18\t \x03(\x02R\tembedding\"\xd9\x01\n" +
	"\x13RegisterFaceRequest\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\x1d\n" +
	"\n" +
	"image_data\x18\x02 \x01(\fR\timageData\x12R\n" +
	"\bmetadata\x18\x03 \x03(\v26.orbo.recognition.v1.RegisterFaceRequest.MetadataEntryR\bmetadata\x1a;\n" +
	"\rMetadataEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\tR\x05value:\x028\x01\"}\n" +
	"\x14RegisterFaceResponse\x12\x18\n" +
	"\asuccess\x18\x01 \x01(\bR\asuccess\x12\x18\n" +
	"\amessage\x18\x02 \x01(\tR\amessage\x12\x12\n" +
	"\x04name\x18\x03 \x01(\tR\x04name\x12\x1d\n" +
	"\n" +
	"face_count\x18\x04 \x01(\x05R\tfaceCount\"'\n" +
	"\x11DeleteFaceRequest\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\"g\n" +
	"\x12DeleteFaceResponse\x12\x18\n" +
	"\asuccess\x18\x01 \x01(\bR\asuccess\x12\x18\n" +
	"\amessage\x18\x02 \x01(\tR\amessage\x12\x1d\n" +
	"\n" +
	"face_count\x18\x03 \x01(\x05R\tfaceCount\"\x12\n" +
	"\x10ListFacesRequest\"b\n" +
	"\x11ListFacesResponse\x127\n" +
	"\x05faces\x18\x01 \x03(\v2!.orbo.recognition.v1.FaceIdentityR\x05faces\x12\x14\n" +
	"\x05count\x18\x02 \x01(\x05R\x05count\"\x8d\x01\n" +
	"\fFaceIdentity\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12\"\n" +
	"\rcreated_at_ns\x18\x02 \x01(\x03R\vcreatedAtNs\x12\x1b\n" +
	"\thas_image\x18\x03 \x01(\bR\bhasImage\x12\x10\n" +
	"\x03age\x18\x04 \x01(\x05R\x03age\x12\x16\n" +
	"\x06gender\x18\x05 \x01(\tR\x06gender\"\x0f\n" +
	"\rHealthRequest\"\xae\x01\n" +
	"\x0eHealthResponse\x12\x16\n" +
	"\x06status\x18\x01 \x01(\tR\x06status\x12\x16\n" +
	"\x06device\x18\x02 \x01(\tR\x06device\x12!\n" +
	"\fmodel_loaded\x18\x03 \x01(\bR\vmodelLoaded\x12*\n" +
	"\x11known_faces_count\x18\x04 \x01(\x05R\x0fknownFacesCount\x12\x1d\n" +
	"\n" +
	"model_name\x18\x05 \x01(\tR\tmodelName\"\xaa\x01\n" +
	"\x10ConfigureRequest\x126\n" +
	"\x14similarity_threshold\x18\x01 \x01(\x02H\x00R\x13similarityThreshold\x88\x01\x01\x12/\n" +
	"\x11enable_age_gender\x18\x02 \x01(\bH\x01R\x0fenableAgeGender\x88\x01\x01B\x17\n" +
	"\x15_similarity_thresholdB\x14\n" +
	"\x12_enable_age_gender\"\xa8\x01\n" +
	"\x11ConfigureResponse\x12\x18\n" +
	"\asuccess\x18\x01 \x01(\bR\asuccess\x12\x18\n" +
	"\amessage\x18\x02 \x01(\tR\amessage\x121\n" +
	"\x14similarity_threshold\x18\x03 \x01(\x02R\x13similarityThreshold\x12,\n" +
	"\x12age_gender_enabled\x18\x04 \x01(\bR\x10ageGenderEnabled2\xc8\x04\n" +
	"\x16FaceRecognitionService\x12Z\n" +
	"\x0fRecognizeStream\x12 .orbo.recognition.v1.FaceRequest\x1a!.orbo.recognition.v1.FaceResponse(\x010\x01\x12c\n" +
	"\fRegisterFace\x12(.orbo.recognition.v1.RegisterFaceRequest\x1a).orbo.recognition.v1.RegisterFaceResponse\x12]\n" +
	"\n" +
	"DeleteFace\x12&.orbo.recognition.v1.DeleteFaceRequest\x1a'.orbo.recognition.v1.DeleteFaceResponse\x12Z\n" +
	"\tListFaces\x12%.orbo.recognition.v1.ListFacesRequest\x1a&.orbo.recognition.v1.ListFacesResponse\x12V\n" +
	"\vHealthCheck\x12\".orbo.recognition.v1.HealthRequest\x1a#.orbo.recognition.v1.HealthResponse\x12Z\n" +
	"\tConfigure\x12%.orbo.recognition.v1.ConfigureRequest\x1a&.orbo.recognition.v1.ConfigureResponseB-Z+orbo/api/proto/recognition/v1;recognitionv1b\x06proto3"

var (
	file_api_proto_recognition_v1_recognition_proto_rawDescOnce sync.Once
	file_api_proto_recognition_v1_recognition_proto_rawDescData []byte
)

func file_api_proto_recognition_v1_recognition_proto_rawDescGZIP() []byte {
	file_api_proto_recognition_v1_recognition_proto_rawDescOnce.Do(func() {
		file_api_proto_recognition_v1_recognition_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_api_proto_recognition_v1_recognition_proto_rawDesc), len(file_api_proto_recognition_v1_recognition_proto_rawDesc)))
	})
	return file_api_proto_recognition_v1_recognition_proto_rawDescData
}

var file_api_proto_recognition_v1_recognition_proto_msgTypes = make([]protoimpl.MessageInfo, 16)
var file_api_proto_recognition_v1_recognition_proto_goTypes = []any{
	(*FaceRequest)(nil),          // 0: orbo.recognition.v1.FaceRequest
	(*BBox)(nil),                 // 1: orbo.recognition.v1.BBox
	(*FaceResponse)(nil),         // 2: orbo.recognition.v1.FaceResponse
	(*FaceRecognition)(nil),      // 3: orbo.recognition.v1.FaceRecognition
	(*RegisterFaceRequest)(nil),  // 4: orbo.recognition.v1.RegisterFaceRequest
	(*RegisterFaceResponse)(nil), // 5: orbo.recognition.v1.RegisterFaceResponse
	(*DeleteFaceRequest)(nil),    // 6: orbo.recognition.v1.DeleteFaceRequest
	(*DeleteFaceResponse)(nil),   // 7: orbo.recognition.v1.DeleteFaceResponse
	(*ListFacesRequest)(nil),     // 8: orbo.recognition.v1.ListFacesRequest
	(*ListFacesResponse)(nil),    // 9: orbo.recognition.v1.ListFacesResponse
	(*FaceIdentity)(nil),         // 10: orbo.recognition.v1.FaceIdentity
	(*HealthRequest)(nil),        // 11: orbo.recognition.v1.HealthRequest
	(*HealthResponse)(nil),       // 12: orbo.recognition.v1.HealthResponse
	(*ConfigureRequest)(nil),     // 13: orbo.recognition.v1.ConfigureRequest
	(*ConfigureResponse)(nil),    // 14: orbo.recognition.v1.ConfigureResponse
	nil,                          // 15: orbo.recognition.v1.RegisterFaceRequest.MetadataEntry
}
var file_api_proto_recognition_v1_recognition_proto_depIdxs = []int32{
	1,  // 0: orbo.recognition.v1.FaceRequest.person_regions:type_name -> orbo.recognition.v1.BBox
	3,  // 1: orbo.recognition.v1.FaceResponse.faces:type_name -> orbo.recognition.v1.FaceRecognition
	1,  // 2: orbo.recognition.v1.FaceRecognition.bbox:type_name -> orbo.recognition.v1.BBox
	15, // 3: orbo.recognition.v1.RegisterFaceRequest.metadata:type_name -> orbo.recognition.v1.RegisterFaceRequest.MetadataEntry
	10, // 4: orbo.recognition.v1.ListFacesResponse.faces:type_name -> orbo.recognition.v1.FaceIdentity
	0,  // 5: orbo.recognition.v1.FaceRecognitionService.RecognizeStream:input_type -> orbo.recognition.v1.FaceRequest
	4,  // 6: orbo.recognition.v1.FaceRecognitionService.RegisterFace:input_type -> orbo.recognition.v1.RegisterFaceRequest
	6,  // 7: orbo.recognition.v1.FaceRecognitionService.DeleteFace:input_type -> orbo.recognition.v1.DeleteFaceRequest
	8,  // 8: orbo.recognition.v1.FaceRecognitionService.ListFaces:input_type -> orbo.recognition.v1.ListFacesRequest
	11, // 9: orbo.recognition.v1.FaceRecognitionService.HealthCheck:input_type -> orbo.recognition.v1.HealthRequest
	13, // 10: orbo.recognition.v1.FaceRecognitionService.Configure:input_type -> orbo.recognition.v1.ConfigureRequest
	2,  // 11: orbo.recognition.v1.FaceRecognitionService.RecognizeStream:output_type -> orbo.recognition.v1.FaceResponse
	5,  // 12: orbo.recognition.v1.FaceRecognitionService.RegisterFace:output_type -> orbo.recognition.v1.RegisterFaceResponse
	7,  // 13: orbo.recognition.v1.FaceRecognitionService.DeleteFace:output_type -> orbo.recognition.v1.DeleteFaceResponse
	9,  // 14: orbo.recognition.v1.FaceRecognitionService.ListFaces:output_type -> orbo.recognition.v1.ListFacesResponse
	12, // 15: orbo.recognition.v1.FaceRecognitionService.HealthCheck:output_type -> orbo.recognition.v1.HealthResponse
	14, // 16: orbo.recognition.v1.FaceRecognitionService.Configure:output_type -> orbo.recognition.v1.ConfigureResponse
	11, // [11:17] is the sub-list for method output_type
	5,  // [5:11] is the sub-list for method input_type
	5,  // [5:5] is the sub-list for extension type_name
	5,  // [5:5] is the sub-list for extension extendee
	0,  // [0:5] is the sub-list for field type_name
}

func init() { file_api_proto_recognition_v1_recognition_proto_init() }
func file_api_proto_recognition_v1_recognition_proto_init() {
	if File_api_proto_recognition_v1_recognition_proto != nil {
		return
	}
	file_api_proto_recognition_v1_recognition_proto_msgTypes[13].OneofWrappers = []any{}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_api_proto_recognition_v1_recognition_proto_rawDesc), len(file_api_proto_recognition_v1_recognition_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   16,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_api_proto_recognition_v1_recognition_proto_goTypes,
		DependencyIndexes: file_api_proto_recognition_v1_recognition_proto_depIdxs,
		MessageInfos:      file_api_proto_recognition_v1_recognition_proto_msgTypes,
	}.Build()
	File_api_proto_recognition_v1_recognition_proto = out.File
	file_api_proto_recognition_v1_recognition_proto_goTypes = nil
	file_api_proto_recognition_v1_recognition_proto_depIdxs = nil
}
